{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the librarires\n",
    "\n",
    "from selenium import webdriver\n",
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We define some basic and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickElement(category, classe, information):\n",
    "    \"\"\"This function allows you to click on an element of the HTML page\"\"\"\n",
    "    element = driver.find_element_by_xpath(\n",
    "        \"//\" + category + \"[@\" + classe + \"='\" + information + \"']\"\n",
    "    )\n",
    "    element.click()\n",
    "\n",
    "\n",
    "def fillField(category, class_name, information, text):\n",
    "    \"\"\"This function allows you to fill in a field of the HTML page\"\"\"\n",
    "    elem = driver.find_element_by_xpath(\n",
    "        \"//\" + category + \"[@\" + class_name + \"='\" + information + \"']\"\n",
    "    )\n",
    "    elem.click()\n",
    "    elem.clear()\n",
    "    elem.send_keys(text)\n",
    "\n",
    "\n",
    "def openLink(link):\n",
    "    \"\"\"This function allows you to open a link\"\"\"\n",
    "    driver.get(link)\n",
    "    time.sleep(6)\n",
    "    \n",
    "\n",
    "# This function will get all the href links that have the a field data-test = \"job-link\"\n",
    "def getAll_JobDescriptionLinks():\n",
    "    \"\"\"This function allows you to get all the href links that have the a field data-test = \"job-link\" \"\"\"\n",
    "    # We get all the links of the page\n",
    "    links = driver.find_elements_by_xpath(\"//a[@data-test='job-link']\")\n",
    "    # We get the href of all the links\n",
    "    hrefs = [link.get_attribute(\"href\") for link in links]\n",
    "    return hrefs\n",
    "\n",
    "def getAll_JobDescriptionLinks_Indeed():\n",
    "    \"\"\"This function allows you to get all the href links that have the a field data-test = \"job-link\" \"\"\"\n",
    "    # We get all the links of the page\n",
    "    links = driver.find_elements_by_xpath(\"//a[@class='jcs-JobTitle css-jspxzf eu4oa1w0']\")\n",
    "    # We get the href of all the links\n",
    "    hrefs = [link.get_attribute(\"href\") for link in links]\n",
    "    return hrefs\n",
    "\n",
    "\n",
    "def assembleLinkGlassdoor(base, job_name, from_age):\n",
    "    \"\"\"This function allows you to assemble the link of the page to be scraped\"\"\"\n",
    "    # Example: https://www.glassdoor.com/Job/machine-learning-jobs-SRCH_KO0,16.htm?fromAge=1\n",
    "    job_name = job_name.replace(\" \", \"-\")\n",
    "    lenght_job_name = len(job_name)\n",
    "    link = base + \"Job/\" + job_name + \"-jobs-SRCH_KO0,\" + str(lenght_job_name) + \".htm?fromAge=\" + str(from_age)\n",
    "    return link\n",
    "\n",
    "\n",
    "def assembleLinkIndeed(base, job_name, from_age, location):\n",
    "    \"\"\"This function allows you to assemble the link of the page to be scraped\"\"\"\n",
    "    # Example: https://www.indeed.com/jobs?q=machine+learning+engineer&l=United+States&fromage=1\n",
    "    job_name = job_name.replace(\" \", \"+\")\n",
    "    location = location.replace(\" \", \"+\")\n",
    "    link = base + \"jobs?q=\" + job_name + \"&l=\" + location + \"&fromage=\" + str(from_age)\n",
    "    return link\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glassdoor Webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the link of the page we want to scrape\n",
    "base = \"https://www.glassdoor.com/\"\n",
    "job_names = [\"machine learning engineer\", \"data scientist\", \"AI engineer\"]\n",
    "from_age = 1\n",
    "\n",
    "\n",
    "def getJobOffer_Glassdoor(base, job_name, from_age):\n",
    "    \"\"\"Get all the job offers for a specific search\"\"\"\n",
    "    # We create the link\n",
    "    link = assembleLinkGlassdoor(base, job_name, from_age)\n",
    "    # We open the link\n",
    "    openLink(link)\n",
    "\n",
    "    # We get all the job offers for this search\n",
    "    job_offers = []\n",
    "    previous_page_offers = []\n",
    "    current_page_offers = []\n",
    "    while True:\n",
    "        # We get all the job offers\n",
    "        current_page_offers = getAll_JobDescriptionLinks()\n",
    "        # We check if the current page offers are the same as the previous page offers\n",
    "        if current_page_offers == previous_page_offers:\n",
    "            break\n",
    "        else:\n",
    "            # We add the current page offers to the job offers\n",
    "            job_offers += current_page_offers\n",
    "            # We update the previous page offers\n",
    "            previous_page_offers = current_page_offers\n",
    "            # We click on the next button\n",
    "            try:\n",
    "                clickElement(\"span\", \"alt\", \"Close\")\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "            clickElement(\"button\", \"aria-label\", \"Next\")\n",
    "            time.sleep(2)\n",
    "    return job_offers\n",
    "\n",
    "\n",
    "def main_Glassdoor(base, job_names, from_age):\n",
    "    \"\"\"Get all the job offers for a list of job names\"\"\"\n",
    "    # We initialize the driver through Firefox\n",
    "    global driver\n",
    "    driver = webdriver.Firefox()\n",
    "    # We get all the job offers for each job name\n",
    "    job_offers = []\n",
    "    for job_name in job_names:\n",
    "        job_offers.append(getJobOffer_Glassdoor(base, job_name, from_age))\n",
    "    # We close the driver\n",
    "    driver.close()\n",
    "    return job_offers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_18048\\3220866325.py:29: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  links = driver.find_elements_by_xpath(\"//a[@data-test='job-link']\")\n",
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_18048\\3220866325.py:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  element = driver.find_element_by_xpath(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glassdoor Web Scraping is done.\n",
      "\n",
      "\n",
      "Saving the Glassdoor data in a csv file is done.\n"
     ]
    }
   ],
   "source": [
    "job_offers = main_Glassdoor(base, job_names, from_age)\n",
    "\n",
    "print(\"Glassdoor Web Scraping is done.\")\n",
    "\n",
    "file_path = \"../data/job_offers_glassdoor.csv\"\n",
    "field_names = [\"link\", \"job_name_searched\", \"date\", \"platform\"]\n",
    "\n",
    "for job_offers, job_name in zip(job_offers, job_names):\n",
    "    with open(file_path, \"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "        # If the file is empty, we write the header\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        for job_offer in job_offers:\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"link\": job_offer,\n",
    "                    \"job_name_searched\": job_name,\n",
    "                    \"date\": time.strftime(\"%Y-%m-%d\"),\n",
    "                    \"platform\": \"glassdoor\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(\"Saving the Glassdoor data in a csv file is done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed WebScrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the link of the page we want to scrape\n",
    "base = \"https://www.indeed.com/\"\n",
    "job_names = [\"machine learning engineer\", \"data scientist\", \"AI engineer\"]\n",
    "from_age = 1\n",
    "location = \"United States\"\n",
    "\n",
    "def getJobOffer_Indeed(base, job_name, from_age, location):\n",
    "    \"\"\"Get all the job offers for a specific search\"\"\"\n",
    "    # We create the link\n",
    "    link = assembleLinkIndeed(base, job_name, from_age, location)\n",
    "    # We open the link\n",
    "    openLink(link)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # We get all the job offers for this search\n",
    "    job_offers = []\n",
    "\n",
    "    while True:\n",
    "        # We get all the job offers of the first page\n",
    "        current_page_offers = getAll_JobDescriptionLinks_Indeed()\n",
    "        # We add the current page offers to the job offers\n",
    "        job_offers += current_page_offers\n",
    "\n",
    "        # We try to click on the next button\n",
    "        try:\n",
    "            clickElement(\"a\", \"data-testid\", \"pagination-page-next\")\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return job_offers\n",
    "\n",
    "\n",
    "def main_Indeed(base, job_names, from_age, location):\n",
    "    \"\"\"Get all the job offers for a list of job names\"\"\"\n",
    "    # We initialize the driver through Firefox\n",
    "    global driver\n",
    "    driver = uc.Chrome(use_subprocess=True)\n",
    "    driver.maximize_window() \n",
    "    # We get all the job offers for each job name\n",
    "    job_offers = []\n",
    "    for job_name in job_names:\n",
    "        job_offers.append(getJobOffer_Indeed(base, job_name, from_age, location))\n",
    "    # We close the driver\n",
    "    driver.close()\n",
    "    return job_offers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_18048\\3220866325.py:37: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  links = driver.find_elements_by_xpath(\"//a[@class='jcs-JobTitle css-jspxzf eu4oa1w0']\")\n",
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_18048\\3220866325.py:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  element = driver.find_element_by_xpath(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed Web Scraping is done.\n",
      "Saving the Indeed data in a csv file is done.\n"
     ]
    }
   ],
   "source": [
    "job_offers = main_Indeed(base, job_names, from_age, location)\n",
    "\n",
    "print(\"Indeed Web Scraping is done.\")\n",
    "\n",
    "file_path = \"../data/job_offers_indeed.csv\"\n",
    "field_names = [\"link\", \"job_name_searched\", \"date\", \"platform\"]\n",
    "\n",
    "for job_offers, job_name in zip(job_offers, job_names):\n",
    "    with open(file_path, \"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "        # If the file is empty, we write the header\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        for job_offer in job_offers:\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"link\": job_offer,\n",
    "                    \"job_name_searched\": job_name,\n",
    "                    \"date\": time.strftime(\"%Y-%m-%d\"),\n",
    "                    \"platform\": \"indeed\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(\"Saving the Indeed data in a csv file is done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
